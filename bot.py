import asyncio
import logging
import re
import requests
import html
import os
from collections import defaultdict
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import Command
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from faster_whisper import WhisperModel

# üîê –¢–æ–∫–µ–Ω –æ—Ç BotFather
API_TOKEN = 'YOUR_TOKEN'

# ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "gemma3:27b"

# üß† –•—Ä–∞–Ω–∏–º –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ user_id
user_histories = defaultdict(list)

# üéüÔ∏è –ó–∞–º–µ–Ω–∞ ** –Ω–∞ <b> –∏ *  –Ω–∞ ‚Äî –¥–ª—è HTML
def convert_to_html(text):
    escaped = html.escape(text)
    bolded = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', escaped)
    bulleted = re.sub(r'^\* ', r'‚Äî ', bolded, flags=re.MULTILINE)
    return bulleted

# üèóÔ∏è –°–æ–±–∏—Ä–∞–µ–º prompt –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
def build_prompt(messages, max_tokens=3000):
    prompt = ""
    total = 0
    for msg in reversed(messages):
        role = "User" if msg["role"] == "user" else "Assistant"
        line = f"{role}: {msg['content']}\n"
        total += len(line.split())
        if total > max_tokens:
            break
        prompt = line + prompt
    return prompt + "Assistant: "

# ü§Ä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper
whisper_model = WhisperModel("base", compute_type="int8_float16")

# üîπ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
async def handle_voice(message: Message, bot: Bot):
    user_id = message.from_user.id
    file = await bot.get_file(message.voice.file_id)
    file_path = f"voice_{user_id}.ogg"
    await bot.download_file(file.file_path, file_path)

    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
    segments, _ = whisper_model.transcribe(file_path)
    text = " ".join(segment.text for segment in segments).strip()
    os.remove(file_path)

    if text:
        await handle_message(types.Message.model_copy(message, update={'text': text}))
    else:
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å :(")

# /start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
async def cmd_start(message: Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Gemma.\n–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –∏–ª–∏ –Ω–∞–¥–∏–∫—Ç—É–π –º–Ω–µ –≤–æ–ø—Ä–æ—Å!")

# üîπ –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
async def handle_message(message: Message):
    user_id = message.from_user.id
    user_input = message.text

    user_histories[user_id].append({"role": "user", "content": user_input})
    prompt = build_prompt(user_histories[user_id])

    # üß† –î—É–º–∞—é...
    await message.answer("üß† –î—É–º–∞—é...")

    try:
        response = requests.post(OLLAMA_URL, json={
            "model": OLLAMA_MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": 400,
                "temperature": 0.7,
                "top_k": 40,
                "top_p": 0.9,
                "repeat_penalty": 1.1,
                "num_ctx": 4096
            }
        })

        if response.status_code == 200:
            model_reply = response.json()["response"].strip()
            user_histories[user_id].append({"role": "assistant", "content": model_reply})

            html_reply = convert_to_html(model_reply)
            await message.answer(html_reply, parse_mode=ParseMode.HTML)
        else:
            await message.answer("–û—à–∏–±–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∞.")
    except Exception as e:
        await message.answer(
            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ Ollama:\n<code>{e}</code>",
            parse_mode=ParseMode.HTML
        )

# üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    logging.basicConfig(level=logging.INFO)

    bot = Bot(
        token=API_TOKEN,
        default=DefaultBotProperties(parse_mode=ParseMode.HTML)
    )
    dp = Dispatcher()

    dp.message.register(cmd_start, Command("start"))
    dp.message.register(handle_voice, lambda msg: msg.voice is not None)
    dp.message.register(handle_message)

    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
