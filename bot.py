import asyncio
import logging
import re
import requests
import html
from collections import defaultdict
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import Command
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties

# üîê –¢–æ–∫–µ–Ω –æ—Ç BotFather
API_TOKEN = 'YOUR_TOKEN'

# ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "gemma3:27b"

# üß† –•—Ä–∞–Ω–∏–º –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ user_id
user_histories = defaultdict(list)

# üéüÔ∏è –ó–∞–º–µ–Ω–∞ ** –Ω–∞ <b> –∏ *  –Ω–∞ ‚Äî –¥–ª—è HTML
def convert_to_html(text):
    escaped = html.escape(text)
    bolded = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', escaped)
    bulleted = re.sub(r'^\* ', r'‚Äî', bolded, flags=re.MULTILINE)
    return bulleted

# üèóÔ∏è –°–æ–±–∏—Ä–∞–µ–º prompt –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
def build_prompt(messages, max_tokens=3000):
    prompt = ""
    total = 0
    for msg in reversed(messages):
        role = "User" if msg["role"] == "user" else "Assistant"
        line = f"{role}: {msg['content']}\n"
        total += len(line.split())
        if total > max_tokens:
            break
        prompt = line + prompt
    return prompt + "Assistant: "

# /start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
async def cmd_start(message: Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Gemma.\n–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(message: Message):
    user_id = message.from_user.id
    user_input = message.text

    user_histories[user_id].append({"role": "user", "content": user_input})
    prompt = build_prompt(user_histories[user_id])

    # üß† –î—É–º–∞—é...
    await message.answer("üß† –î—É–º–∞—é...")

    try:
        response = requests.post(OLLAMA_URL, json={
            "model": OLLAMA_MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": 200,
                "temperature": 0.7,
                "top_k": 40,
                "top_p": 0.9,
                "repeat_penalty": 1.1,
                "num_ctx": 4096
            }
        })

        if response.status_code == 200:
            model_reply = response.json()["response"].strip()
            user_histories[user_id].append({"role": "assistant", "content": model_reply})

            html_reply = convert_to_html(model_reply)
            await message.answer(html_reply, parse_mode=ParseMode.HTML)
        else:
            await message.answer("–û—à–∏–±–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∞.")
    except Exception as e:
        await message.answer(
            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ Ollama:\n<code>{e}</code>",
            parse_mode=ParseMode.HTML
        )

# üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    logging.basicConfig(level=logging.INFO)

    bot = Bot(
        token=API_TOKEN,
        default=DefaultBotProperties(parse_mode=ParseMode.HTML)
    )
    dp = Dispatcher()

    dp.message.register(cmd_start, Command("start"))
    dp.message.register(handle_message)

    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
